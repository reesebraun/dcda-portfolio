<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Skills Portfolio showcasing work from DCDA 40833">
    <meta name="author" content="Reese Braun">
    <title> Lab 02: Evaluating AI Tools</title>
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <!-- Navigation: Links to all portfolio pages -->
    <nav>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="lab02.html">AI Evaluation</a></li>
            <li><a href="tufte-critique.html">Tufte Critique</a></li>
            <li><a href="tableau-visualization.html">Tableau Viz</a></li>
            <li><a href="lab5.html">Lab 5</a></li>
            <li><a href="hometown-map.html">Hometown Map</a></li>
        </ul>
    </nav>

    <!-- Header: Your name and course info -->
     <!-- Updated the header to display my name so visitors immediately know
     whose portfolio this is -->
    <header>
        <h1>Lab 2: AI Tool Evaluation</h1>
        <p>DCDA 40833 Skills Portfolio | Spring 2026</p>
    </header>

 <main>
        <!-- Overview Section: Brief introduction to the lab -->

        <section>
  <h2>Overview</h2>
  <p>In this lab, I evaluated two AI tools‚ÄîCanva AI and Claude‚Äîusing a framework focused on capabilities, appropriate use, and ethical considerations.</p>
</section>

<section>
  <h2>Tool 1: Canva AI</h2>
     <p>
    I tested Canva AI‚Äôs design capabilities using accessibility-focused prompts to see how well it handles
    WCAG readability/contrast guidance, inclusive palettes, and more complex accessibility constraints.
    I documented each prompt, Canva‚Äôs output, and what the result suggests about the tool‚Äôs strengths and limits.
  </p>


  <h3>Evidence: Prompts + Outputs</h3>
  <!-- Prompt 1 card -->
 <div class="prompt-card">
    <h4>Prompt 1: WCAG Accessibility (Baseline)</h4>
    <p><strong>Prompt:</strong> ‚ÄúDesign a social media post announcing a sustainability event that meets WCAG accessibility standards for color contrast and readability.‚Äù</p>
    
    <div class="image-row">
  <figure>
    <img src="images/Instagram Post - Join the Sustainability Movement.jpg"
         alt="First Canva AI WCAG-focused sustainability post">
    <figcaption>Initial Canva AI WCAG-focused output.</figcaption>
  </figure>

  <figure>
    <img src="images/Sustainability Event Poster - Urban Park.jpg"
         alt="Second Canva AI WCAG-focused sustainability post">
    <figcaption>Alternate Canva AI WCAG-focused variation.</figcaption>
  </figure>
</div>
 <p><strong>Takeaway:</strong>
    Both outputs prioritize clean hierarchy and readable text, but accessibility is treated as a visual approximation rather than a verified standard.
  </p>
</div>


  <!-- Prompt 2 card -->
  <div class="prompt-card">
    <h4>Prompt 2: Color-blind Friendly + Low Vision + Alt Text</h4>
    <p><strong>Prompt:</strong> ‚ÄúCan you use a color-blind friendly palette, readable hierarchy for low vision, and alt-text suggestions?‚Äù</p>
  <div class="single-image">
  <figure>
    <img src="images/Instagram Post - Join Our Sustainability Event!.jpg"
         alt="Canva AI redesign using a color-blind friendly palette and clearer hierarchy for low vision.">
    <figcaption>Revised output: improved hierarchy and simplified layout, but some light text on pale backgrounds may still fail contrast standards.</figcaption>
  </figure>
  </div>
    <p><strong>Takeaway:</strong> Canva responds well to accessibility language, but may introduce new contrast issues‚Äîsuggesting accessibility is treated as an aesthetic adjustment, not a measurable standard.</p>
  </div>

  <!-- Prompt 3 card -->
 <div class="prompt-card">
    <h4>Prompt 3: WCAG AA Contrast Verification (Claims vs Proof)</h4>
    <p><strong>Prompt:</strong> ‚ÄúRedesign this post so that all text meets WCAG AA contrast ratios. Please specify which text/background combinations meet the standard.‚Äù</p>
    <div class="single-image"></div>
    <figure>
      <img src="images/Instagram Post - Sustainable Solutions for Tomorrow  .jpg" alt="Canva AI redesign with darker background and higher contrast text for WCAG AA." />
      <figcaption>
        Higher-contrast redesign: visually improved readability, but no contrast values or verification were provided despite the prompt.
      </figcaption>
    </figure>
 </div>
    <p><strong>Takeaway:</strong> Canva can redesign toward accessibility, but it does not audit or confirm WCAG AA compliance‚Äîverification still requires external checking and human review.</p>
  </div>

  <!-- Prompt 4 card -->

  <div class="prompt-card">
    <h4>Prompt 4: Motion + Cognitive Accessibility (Limit Test)</h4>
    <p><strong>Prompt:</strong> ‚ÄúCreate a short animated version of this post that is accessible for users with cognitive disabilities and motion sensitivity.‚Äù</p>
      <figcaption>
        Capability boundary: Canva AI stated it cannot reliably add text to videos and suggested adding text manually after generation.
      </figcaption>
    </figure>
    <p><strong>Takeaway:</strong> When accessibility constraints become multi-layered (motion sensitivity + cognition + text timing), Canva AI cannot fully execute the task and shifts responsibility back to the user.</p>
  </div>

  <h3>Capabilities</h3>
  <p>
    Across the four tests, Canva AI was strongest at quickly producing polished layouts with clear hierarchy and a cohesive
    visual style. It responded to accessibility-oriented prompting by simplifying structure and increasing contrast in later
    iterations. However, the tool struggled with technical specificity: it did not provide measurable WCAG contrast proof,
    and it hit a clear limitation when asked to generate motion-accessible video that includes text. Overall, Canva AI
    behaves like a fast design assistant rather than an accessibility-aware system.
  </p>


  <h3>Appropriate Use</h3>
   <p>
    Canva AI is best used for early-stage drafting‚Äîquickly exploring layouts, visual directions, and accessibility-informed
    starting points. It becomes less appropriate when a project requires verified standards (WCAG AA compliance), nuanced
    accessibility needs (motion sensitivity), or accurate documentation of compliance. The most responsible workflow is:
    generate a draft with Canva AI, then refine intentionally and validate accessibility using external tools and human judgment.
  </p>

  <h3>Ethical Considerations</h3>
  <p>
    The biggest ethical risk I observed is ‚Äúconfidence without verification.‚Äù Canva AI can present outputs as accessible,
    but it does not reliably confirm compliance or provide evidence (contrast ratios, verified pairings). In public-facing or
    institutional communication, this can create a false sense of inclusion. Accessibility is not just a visual style‚Äîit
    affects who can participate. These tests reinforced that designers must take responsibility for validation and avoid
    treating AI-generated accessibility as automatically correct.
  </p>
</section>


  <section id="claude-ai">
<h2>Tool 2: Claude</h2>
  <p>
    To complement my evaluation of Canva AI‚Äôs visual design capabilities,
    I tested Claude as a text-based AI assistant with a focus on accessibility,
    ethical reasoning, and transparency.
  </p>

  <h3>Evidence: Prompts + Outputs</h3>
<div class="prompt-card">
  <h4>Claude Prompt 1: Accessibility-Focused Caption</h4>

  <p><strong>Prompt:</strong>
    Write an Instagram caption promoting a sustainability event that is accessible to users with cognitive disabilities and low vision.
  </p>

  <p><strong>Output (excerpt):</strong></p>
  <blockquote>
    <p><strong>Join us for Green Future Day! üå±</strong></p>
    <p>Saturday, March 15<br>
    10 AM to 4 PM<br>
    Community Center, 123 Main Street</p>

    <p>Learn easy ways to help the planet.</p>

    <p><strong>What you'll do:</strong><br>
    ‚Ä¢ Make a reusable tote bag<br>
    ‚Ä¢ Plant seeds to take home<br>
    ‚Ä¢ Learn simple recycling tips<br>
    ‚Ä¢ Enjoy free snacks and drinks</p>

    <p>Free event. Everyone welcome.</p>

    <p>Questions? Call us at 555-0123 or email hello@greenfuture.org</p>
  </blockquote>

  <p><strong>Claude‚Äôs accessibility notes (excerpt):</strong></p>
  <blockquote>
    <p>Short sentences, simple words, clear structure with spacing, bullet points, minimal emoji use, and reminders to add alt text and use high contrast.</p>
  </blockquote>

  <p><strong>Short statement (what this shows):</strong>
    Claude performed well as a writing assistant for accessibility by producing clear, structured copy and explicitly explaining why specific choices support users with cognitive disabilities and low vision.
    It also acknowledged limits by noting that readability still depends on font size and contrast in the final graphic.
  </p>
</div>
<div class="prompt-card">
  <h4>Claude Prompt 2: Ethical Risks in Sustainability Messaging</h4>

  <p><strong>Prompt:</strong>
    What are the ethical risks of using AI tools to create sustainability messaging?
  </p>

  <p><strong>Output (excerpt):</strong></p>
  <blockquote>
    <p><strong>Greenwashing and misleading claims:</strong>
    AI tools may generate compelling but inaccurate sustainability claims. Without human fact-checking,
    organizations risk spreading misinformation or exaggerating environmental impact.</p>

    <p><strong>Equity and accessibility concerns:</strong>
    AI-generated messaging may default to perspectives that resonate with privileged audiences while
    overlooking environmental justice issues and marginalized communities.</p>

    <p><strong>Bias in training data:</strong>
    AI systems reflect biases in their training data, often emphasizing individual consumer action over
    systemic change or prioritizing Western sustainability narratives.</p>

    <p><strong>Authenticity and trust:</strong>
    Over-reliance on AI-generated messaging can feel impersonal, potentially undermining trust and
    genuine community engagement.</p>
  </blockquote>
</div>

<div class="prompt-card">
  <h4>Claude Prompt 3: Verification and Limits</h4>

  <p><strong>Prompt:</strong>
    Can you guarantee that AI-generated sustainability messaging meets accessibility or ethical standards? Explain why or why not.
  </p>

  <p><strong>Output (excerpt):</strong></p>
  <blockquote>
    <p><strong>No, I cannot guarantee that AI-generated sustainability messaging meets accessibility or ethical standards.</strong></p>

    <p><strong>Accessibility requires real-world testing:</strong>
    True accessibility means testing with actual users who have disabilities. Only real people in real contexts can determine
    whether content is usable and inclusive.</p>

    <p><strong>Context matters enormously:</strong>
    Ethical standards depend on factors I may not fully understand, including an organization‚Äôs real environmental practices,
    cultural context, and power dynamics.</p>

    <p><strong>No substitute for human judgment:</strong>
    Ethical decisions require accountability, lived experience, and moral responsibility that AI systems do not possess.</p>
  </blockquote>
</div>
<div class="prompt-card">
  <h4>Claude Prompt 4: Accessible Design Planning (Conceptual)</h4>

  <p><strong>Prompt:</strong>
    Describe how you would design an accessible Instagram post announcing a sustainability event.
    Explain your design choices, including color contrast, text hierarchy, motion considerations, and alt text.
  </p>

  <p><strong>Output (excerpt):</strong></p>
  <blockquote>
    <p><strong>Color contrast and hierarchy:</strong>
    Use a contrast ratio of at least 4.5:1 for normal text and 3:1 for large text, following WCAG AA standards.
    Establish a clear hierarchy with a large headline, medium-sized key details, and readable supporting text,
    using simple sans-serif fonts.</p>

    <p><strong>Motion and cognitive accessibility:</strong>
    Avoid flashing elements or rapid animations. If animation is used, keep transitions slow and smooth and
    provide a static alternative to reduce cognitive and vestibular strain.</p>

    <p><strong>Limits of AI:</strong>
    As an AI, I can describe accessibility principles but cannot create or verify the final visual design.
    A human designer must implement these choices and test them with real users to ensure accessibility.</p>
  </blockquote>
</div>


   <!-- Claude prompts will go here -->

<h3>Capabilities</h3>
<p>
  Claude demonstrated strong capabilities as a text-based reasoning and writing assistant, particularly in contexts involving
  accessibility and ethics. Across all prompts, Claude consistently produced clear, well-structured language and showed an
  explicit understanding of accessibility principles such as simplified wording, logical hierarchy, and audience-aware
  communication. A key strength of Claude is its ability to explain <em>why</em> certain choices support accessibility, not
  just what those choices are.
</p>

<p>
  Unlike visual design tools, Claude repeatedly emphasized its own limitations. It avoided claiming compliance with
  accessibility or ethical standards and instead highlighted the need for real-world testing, contextual knowledge, and
  human verification. However, Claude‚Äôs capabilities remain conceptual rather than executable‚Äîit cannot create or validate
  visual designs or confirm real-world outcomes. Its value lies in planning, explanation, and reflection rather than
  implementation.
</p>

<h3>Appropriate Use</h3>
<p>
  Claude is best suited for early-stage drafting, planning, and ethical reasoning within academic and professional workflows.
  It works especially well as a tool for developing accessible copy, outlining design principles, and prompting critical
  reflection on inclusivity and responsibility. In this project, Claude complemented Canva AI by providing conceptual and
  ethical guidance that visual tools often lack.
</p>

<p>
  Claude is not appropriate for final decision-making or compliance validation. Treating it as an authority on accessibility
  or ethics would be a misuse of the tool, as it cannot account for specific audiences, organizational contexts, or lived user
  experiences. The most effective workflow positions Claude as a thinking partner that supports, rather than replaces,
  human judgment.
</p>

<h3>Ethical Considerations</h3>
<p>
  Ethically, Claude adopts a cautious and transparent stance. It consistently redirects responsibility back to human users
  and acknowledges risks such as greenwashing, bias in training data, oversimplification of sustainability narratives, and
  the exclusion of marginalized perspectives. This refusal to overclaim authority reduces the risk of misleading or
  exclusionary communication.
</p>

<p>
  At the same time, Claude‚Äôs responses highlight a core limitation of AI systems: ethical decisions require lived experience,
  contextual awareness, and accountability‚Äîqualities AI does not possess. While Claude can raise concerns and suggest best
  practices, responsibility for ethical outcomes ultimately rests with human creators.
</p>
  </section>

<section id="comparison">
    <h2>Comparison: Canva AI vs. Claude</h2>

<p>
  Evaluating both <strong> Canva AI </strong> and
  <strong> Claude</strong> using the same framework
  revealed that these tools approach accessibility, ethics, and responsibility in fundamentally different ways.
  While both are positioned as ‚Äúassistive‚Äù AI systems, they embed very different values in how they respond to user prompts.
</p>

<h3>Capabilities Compared</h3>
<p>
  Canva AI excels at rapid visual execution. It can quickly generate polished layouts and adapt designs in response
  to accessibility-related language, such as requests for improved hierarchy or higher contrast. However, its
  capabilities are largely aesthetic and approximative. Canva AI often presents outputs as accessible without
  verifying technical standards, such as WCAG contrast ratios, and struggles when multiple accessibility constraints
  (motion sensitivity, cognitive load, and text behavior) are combined.
</p>

<p>
  Claude, by contrast, does not execute visual designs at all. Its strength lies in explanation, reasoning, and
  structured communication. Claude consistently articulated accessibility principles, ethical risks, and limitations,
  emphasizing why certain choices matter rather than simply producing an output. While Claude cannot implement or
  validate designs, it demonstrated a stronger ability to reason through complexity and uncertainty.
</p>

<h3>Appropriate Use Compared</h3>
<p>
  Canva AI is best suited for early-stage visual drafting and exploration. It is effective for generating starting
  points, testing layout ideas, and reducing technical barriers to design. However, it becomes less appropriate when
  projects require verified accessibility compliance or ethical accountability, as it cannot independently audit
  or confirm its outputs.
</p>

<p>
  Claude is most effective as a planning and reflection tool. It supports drafting accessible language, identifying
  ethical risks, and guiding human decision-making before implementation. Treating Claude as a final authority or
  compliance checker would be inappropriate, but using it as a thinking partner strengthens the overall workflow.
</p>

<h3>Ethical Orientation Compared</h3>
<p>
  One of the most significant differences between the tools is how they handle ethical responsibility.
  Canva AI tends to act confidently, redesigning content in response to accessibility prompts without clearly
  acknowledging uncertainty or limitations. This can create a false sense of inclusion if users assume accessibility
  has been fully addressed.
</p>

<p>
  Claude, on the other hand, repeatedly refused to guarantee ethical or accessible outcomes. It explicitly stated
  that real-world testing, contextual knowledge, and human judgment are essential. This restraint reduces the risk
  of misleading claims and highlights that ethical responsibility cannot be automated.
</p>
</section>


<section id="reflection">

  <h2>Broader Reflection</h2>

  <h3>Personal Use</h3>
<p>
  In my own academic and professional work, I would use AI tools as collaborators rather than authorities.
  Tools like Canva AI are valuable for accelerating early-stage design and experimentation, while tools like Claude
  support clearer thinking, ethical framing, and accessible communication. However, neither tool should be treated
  as a replacement for human judgment. Final decisions‚Äîespecially those involving accessibility, ethics, or public
  messaging‚Äîrequire verification, reflection, and accountability that AI systems cannot provide.
</p>

<h3>DCDA Context</h3>
<p>
  Within the Digital Culture and Data Analytics program, AI tools can enhance skills such as prototyping, iteration,
  and content generation. They lower technical barriers and allow students to focus more on ideas and storytelling.
  At the same time, overreliance on AI risks weakening critical skills central to DCDA, including ethical reasoning,
  contextual analysis, and audience awareness.
</p>

<p>
  What remains uniquely human in digital culture and data analytics work is the ability to interpret meaning,
  question assumptions, and take responsibility for impact. AI can assist with execution and explanation, but it
  cannot fully understand cultural context, lived experience, or moral consequence.
</p>

<h3>Evolving Landscape</h3>
<p>
  As AI tools continue to evolve, evaluating them requires asking deeper questions than whether they are efficient
  or impressive. Important questions include: What does this tool claim to do versus what it can verify? What values
  are embedded in how it responds to users? Who is responsible when the output causes harm or exclusion? And how
  transparent is the system about its limitations?
</p>

<p>
  Asking these questions ensures that AI adoption remains thoughtful, ethical, and aligned with human-centered
  design principles rather than driven solely by convenience or speed.
</p>
</section>

 
</main>


    <!-- Footer: Links and copyright -->
    <footer>
        <p><a href="https://github.com/reesebraun/your-repo-name">View Repository on GitHub</a></p>
        <p>&copy; 2026 Reese Braun | DCDA 40833 | TCU</p>
    </footer>
</body>
</html>
